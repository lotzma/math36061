\documentclass{article}
% Include macros here
\input{macros}
\usepackage{fancyhdr}
%\include{macros}
\usepackage{pifont}

% Number of problem sheet
\newcounter{problemSheetNumber}
\setcounter{problemSheetNumber}{5}
\newcommand{\matlabprob}{\ding{100} \ }
\newcommand{\examprob}{\ding{80} \ }
%\setcounter{section}{\theproblemSheetNumber}  
%\renewcommand{\theparagraph}{(\thesection.\arabic{paragraph})}
\newcounter{problems}
\setcounter{problems}{3}
%\setlength{\parindent}{0cm}
\renewcommand{\problem}[1]{\paragraph{(\theproblemSheetNumber.\theproblems)}\addtocounter{problems}{1}\label{#1}}
\renewcommand{\solution}[1]{\paragraph{Solution (\theproblemSheetNumber.\theproblems)}\addtocounter{problems}{1}\label{#1}}

\setcounter{MaxMatrixCols}{20}

\pagestyle{fancy}
\lhead{MATH36061}
\chead{Convex Optimization}
\rhead{November 18, 2016}

\begin{document} 
\begin{center}
{\Large {\bf Solutions to Part B of Problem Sheet \theproblemSheetNumber}}
\end{center}



\solution{} The last block of rows reads as
\begin{equation*}
 \mtx{S}\Delta\vct{x}+\mtx{X}\Delta\vct{s}=-\mtx{XS}\vct{e}+\sigma \mu \vct{e},
\end{equation*}
so that multiplying by $\mtx{X}^{-1}$ (the diagonal matrix $\mtx{X}$ is non-singular, since we are in $\mathcal{F}^{\circ}$) and solving for $\Delta\vct{s}$, we get
\begin{equation*}
 \Delta \vct{s} = -\mtx{S}\vct{e}-\mtx{X}^{-1}\mtx{S}\Delta\vct{x}+\sigma \mu \mtx{X}^{-1}\vct{e}.
\end{equation*}
Substituting $\Delta \vct{s}$ into the first block of rows, we get
\begin{equation*}
 \mtx{A}^\trans \Delta \vct{y}+\mtx{X}^{-1}\mtx{S}\Delta\vct{x}=\mtx{S}\vct{e}-\sigma \mu \mtx{X}^{-1}\vct{e}.
\end{equation*}
Using $\mtx{D}=\mtx{S}^{-1/2}\mtx{X}^{1/2}$, we get the new system
\begin{align}\label{eq:1}\tag{1}
\begin{pmatrix}
  \zerovct & \mtx{A}\\
  \mtx{A}^{\trans} & -\mtx{D}^{-2}
 \end{pmatrix} 
 \begin{pmatrix}
  \Delta \vct{y}\\ \Delta \vct{x}
 \end{pmatrix} &= \begin{pmatrix} \zerovct \\ 
\mtx{s}-\sigma \mu \mtx{X}^{-1}\vct{e}
\end{pmatrix}\\
\label{eq:2}\tag{2}
\Delta \vct{s} &= -\mtx{S}\vct{e}-\mtx{X}^{-1}\mtx{S}\Delta\vct{x}+\sigma \mu \mtx{X}^{-1}\vct{e}.
\end{align}
Multiplying $\mtx{A}\mtx{D}^2$ to the second block of rows, we get
\begin{equation*}
 \mtx{AD}^2\mtx{A}^\trans\Delta \vct{y}-\mtx{A}\Delta\vct{x} = \mtx{A}\mtx{D}^2\vct{s}-\sigma\mu\mtx{A}\mtx{D}^2\mtx{X}^{-1}\vct{e},
\end{equation*}
which in view of $\mtx{A}\Delta\vct{x}=\zerovct$, $\mtx{D}^{2}\mtx{X}^{-1}=\mtx{S}^{-1}$ and $\mtx{D}^2\vct{s} = \vct{x}$ simplifies to
\begin{equation*}
 (\mtx{AD}^2\mtx{A}^\trans) \Delta \vct{y} = \mtx{b}-\sigma\mu\mtx{A}\mtx{S}^{-1}\vct{e}.
\end{equation*}
This gives a system of equations for recovering $\Delta\vct{y}$, with a symmetric coefficient matrix $\mtx{A}\mtx{D}^2\mtx{A}^{\trans}$. From the second block of~\eqref{eq:1} we also get
\begin{equation*}
 \mtx{X}^{-1}\mtx{S}\Delta \vct{x}-\sigma \mu \mtx{X}^{-1}\vct{e}=\mtx{A}^{\trans}\Delta \vct{y}-\vct{s},
\end{equation*}
and substituting this into the expression for $\Delta \vct{s}$ in~\eqref{eq:2} above gives
\begin{equation*}
 \Delta \vct{s} = -\mtx{A}^{\trans} \Delta \vct{y}.
\end{equation*}
Finally, we can obtain $\Delta\vct{x}$ from $\Delta\vct{s}$ via~\eqref{eq:2},
\begin{equation*}
 \Delta\vct{x} = -\vct{x}-\mtx{S}^{-1}\mtx{X}\Delta \vct{s}+\sigma \mu \mtx{S}^{-1}\vct{e}.
\end{equation*}
This is the last of the three equations. The benefit is that one only has to solve one system of equations with symmetric coefficient matrix $\mtx{A}\mtx{D}^2\mtx{A}^{\trans}$, which can be done efficiently using, for example, Cholesky factorization or other methods. Once $\Delta\vct{y}$ is found, one can compute the other parts $\Delta\vct{x}$ and $\Delta\vct{s}$ easily.
\end{document}
