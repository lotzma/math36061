\documentclass{article}
% Include macros here
\input{macros}
\usepackage{fancyhdr}
%\include{macros}
\usepackage{pifont}

% Number of problem sheet
\newcounter{problemSheetNumber}
\setcounter{problemSheetNumber}{4}
\newcommand{\matlabprob}{\ding{100} \ }
\newcommand{\examprob}{\ding{80} \ }
%\setcounter{section}{\theproblemSheetNumber}  
%\renewcommand{\theparagraph}{(\thesection.\arabic{paragraph})}
\newcounter{problems}
\setcounter{problems}{0}
%\setlength{\parindent}{0cm}
\renewcommand{\problem}{\paragraph{(\theproblemSheetNumber.\theproblems)}\addtocounter{problems}{1}}

%\theoremstyle{remark}
%\newtheorem{problem}[problemSheetNumber]{}

\pagestyle{fancy}
\lhead{MATH36061}
\chead{Convex Analysis}
\rhead{October 23, 2016}

\begin{document} 
\begin{center}
{\Large {\bf Problem Sheet \theproblemSheetNumber}}
\end{center}

Problems in Part A will be discussed in class.
Problems in Part B come with solutions and should be tried at home. 

\section*{Part A}

\problem For the following linear programming problems,
\begin{align}\label{eq:ex1}\tag{LP1}
\begin{split}
 \maximize & x_1+2x_2 \\
 \subjto &x_1+x_2\leq 2\\
 & x_1-x_2\leq 1\\
 &x_1\geq -1
\end{split}
\end{align}
\begin{align}\label{eq:ex1}\tag{LP2}
\begin{split}
 \maximize & x_1+x_2 \\
 \subjto
 & x_2-x_1\leq 2\\
 & x_1+x_2\leq 8\\
 &x_1+2x_2\leq 10\\
 &x_1\leq 4\\
 &x_1\geq 0\\
 &x_2\geq 0.
\end{split}
\end{align}

\begin{itemize}
 \item[(a)] Sketch the polyhedron of feasible points and find the vertices;
 \item[(b)] Find a solution, if it exists (you can find the solution visually, but you may use a computer program such as CVXPY in Python or CVX in MATLAB to verify the result).
\end{itemize}

\problem Given a matrix $\mtx{A}\in \R^{m\times n}$ and $\vct{b}\in \R^m$ such that the polyhedron $P=\{\vct{x}\in \R^n\mid \mtx{A}\vct{x}\leq \vct{b}\}$ is not empty and bounded. 
Show that if the optimal value of
\begin{equation*}
 \maximize \ip{\vct{c}}{\vct{x}} \quad \subjto \mtx{A}\vct{x}\leq \vct{b}
\end{equation*}
is finite, it is attained at a vertex $\vct{x}^*$ of $P$. 

\problem Formulate the following optimization problem as a linear programming problem,
\begin{equation*}
 \minimize \norm{\vct{x}}_1 \quad \subjto \mtx{A}\vct{x}=\vct{b},
\end{equation*}
and describe the dual problem.

\problem Show that there exists a vector $\vct{x}\neq \zerovct$ satisfying 
\begin{equation}\label{eq:primal}\tag{P}
 \vct{x}\geq 0, \quad \mtx{A}\vct{x}=\zerovct
\end{equation}
if and only if there is no vector $\vct{y}$ such that
\begin{equation}\label{eq:dual}\tag{D}
 \mtx{A}^{\trans}\vct{y}>\zerovct.
\end{equation}
Give a geometric interpretation of this fact.

\newpage

\section*{Part B}
\problem (Compressive Sensing) Consider a signal $f\colon [0,2\pi]\to \R$
with the property that $f(0)=f(2\pi)$. In practice, one often does not see the whole signal, but only samples certain values at discrete time intervals. It turns out that optimization can help to reconstruct a signal using much fewer samples than commonly thought possible.

\begin{figure}[h!]
 \centering
 \includegraphics[width=0.6\textwidth]{images/subsample_cropped.pdf}
 \caption{Signal sampled at 30 points, and reconstructed from these.}
\label{fig:subsample}
\end{figure}

To understand how the reconstruction from few samples works, we have to look at the Fourier Transform. A periodic function can be written as a Fourier Series
\begin{equation*}
 f(x) = \frac{a_0}{2}+\sum_{n=1}^\infty a_n\cos(nx)+b_n\sin(nx).
\end{equation*}
Setting $c_n=(a_n+ib_n)/2$, $c_{-n}=(a_n-ib_n)/2$ for $n>0$, and $c_0=a_0/2$, the series can also be written in exponential form as as
\begin{equation}\label{eq:fourier-series}\tag{1}
 f(x) = \sum_{n=-\infty}^\infty c_n e^{inx},
\end{equation}
where $e^{ix} = \cos(x)+i\sin(x)$ and $i=\sqrt{-1}$. While this representation involves complex numbers, the resulting function is real due to the way the imaginary parts in the summands combine. 
We can obtain the coefficients $c_n$ in the series~\eqref{eq:fourier-series} by computing
\begin{equation*}
 c_n = \hat{f}(n) := \frac{1}{2\pi} \int_0^{2\pi} f(x) e^{-inx} \ dx.
\end{equation*}
The operation $f\mapsto \hat{f}$ is called the {\em Fourier Transform}. A characteristic feature of many signals is that they are {\em sparse} in the Fourier domain, meaning that only very few summands in the expansion~\eqref{eq:fourier-series} are necessary to describe the signal accurately (in two dimensions, this principle is the basis of the JPEG image compression standard). For the particular function shown in Figure~\ref{fig:subsample}, the representation is 
\begin{equation}\label{eq:signal}\tag{2}
 f(x) = 0.5\sin(5x)+0.5\cos(9x)-\cos(11x)+0.2\sin(13x)+1.7\sin(30x).
\end{equation}

Often we are not so much interested in the analytic expression for the function $f$ but in its values at a discrete set of points
\begin{equation*}
 x_0=0, \quad x_n=2\pi, \quad x_k=\frac{2\pi k}{n}.
\end{equation*}
The goal of reconstructing $f$ then becomes the reconstruction of {\em all} values $f_j=f(x_j)$ from the knowledge of only a few samples $f_k$, $k\in I\subset \{0,\dots,n-1\}$, $|I|=m<n$. 

The function is now represented by a {\em vector} $\vct{f}=(f_0,\dots,f_{n-1})^{\trans}$. The {\em discrete Fourier transform} $\mathrm{DFT}_n(f)$ is a vector $\vct{c}=(c_0,\dots,c_{n-1})^{\trans}$ such that
\begin{equation}\label{eq:discrete-fourier-sum}\tag{3}
 f_j := f(x_j) = \frac{1}{n}\sum_{k=0}^{n-1} c_k e^{ik\frac{2\pi j}{n}}
\end{equation}
for $j=0,\dots,n-1$.
Computing the DFT amounts to solving a linear system
\begin{equation}\label{eq:dft}\tag{4}
 \vct{f} = \mtx{D} \vct{c},
\end{equation}
where the matrix $\mtx{D}$ has the entries $\mtx{D} = (e^{i\frac{2\pi jk}{n}}/n)_{0\leq j,k\leq n-1}$.
The DFT can be computed using the Fast Fourier Transform in $O(n\log n)$ operations. 
Vectors $\vct{f}$ that come from the discretisation of signals like~\eqref{eq:signal} have the property that the {\em Fourier coefficients} $\mathrm{DFT}_n(f)=\vct{c}$ are {\em sparse}, i.e., have only few non-zero entries, see Figure~\ref{fig:fourierex}.

\begin{figure}[h!]
 \centering
 \includegraphics[width=0.6\textwidth]{images/fourier_cropped.pdf}
 \caption{Sparse DFT for signal from Figure~\ref{fig:subsample}.}\label{fig:fourierex}
\end{figure}

The sparsity of DFT vector is the key reason why the following approach for reconstructing $\vct{f}$ from few samples $\vct{f}_I$ works. Consider the optimization problem
\begin{align}\label{eq:l1min}\tag{5}
\begin{split}
 \minimize & \norm{\vct{c}}_1,\\
 \subjto & \mtx{D}_I\vct{c} = \vct{f}_I,
\end{split}
 \end{align}
with the function given as in~\eqref{eq:signal}, where $I\subset[n]$ and $\mtx{D}_I$ is the matrix consisting of the rows indexed by $I$ and $\mtx{f}_I$ the subvector indexed by the entries of $I$ (the red dots in Figure~\ref{fig:subsample}). For example,
\begin{equation*}
 \mtx{D} = \begin{pmatrix} 1 & 2 & 3\\
            2 & 3 & 4\\
            3 & 4 & 5
           \end{pmatrix},
\ I=\{1,3\}, \quad \Longrightarrow \mtx{D}_I = \begin{pmatrix} 1 & 2 & 3\\
            3 & 4 & 5
           \end{pmatrix}
\end{equation*}
In words, we are looking for a vector $\vct{c}$ of minimal $1$-norm that satisfies {\em a small part} of the quadratic system of equations~\eqref{eq:dft}. Once we have such a solution $\hat{\vct{c}}$, the hope is that $\mtx{D}\hat{\vct{c}}=\vct{f}$ gives back the full vector. 

\begin{itemize}
 \item[(a)] Formulate the conditions $\mtx{D}_I\vct{c}=\vct{f}_I$ as {\em linear} constraints involving real numbers. Hint: split $\vct{c}$ and $\mtx{D}_I$ in real and imaginary parts and reformulate the matrix-vector product accordingly.
\item[(b)] Solve the optimization problem~\eqref{eq:l1min} as follows.
\begin{itemize}
\item Set $n=512$ and generate points $x_i=2\pi j/n$ with corresponding values $f_j=f(x_j)$. 
\item Generate the matrix $\mtx{D}$ (in Python, using {\tt numpy.ifft;}) and
choose a random set of $50$ indices to generate a matrix $\mtx{D}_I$ and $\vct{f}_I$. 
\item Using CVX, solve the optimization problem~\eqref{eq:l1min} and compare the computed vector $\hat{\vct{f}}$ with the original $\vct{f}$.
\end{itemize}
\item[(c)] Repeat the experiment in Part (b) with different values of $m$ in order to determine how many samples are necessary to reconstruct the vector $\vct{f}$ accurately.
\item[(d)] Reformulate~\eqref{eq:l1min} as a linear programming problem.
\end{itemize}


\end{document}
