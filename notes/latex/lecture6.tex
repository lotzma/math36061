%-----------------------------------------------------------------------
% Beginning of chap2.tex
%-----------------------------------------------------------------------
%
%  AMS-LaTeX sample file for a chapter of a monograph, to be used with
%  an AMS monograph document class.  This is a data file input by
%  chapter.tex.
%
%  Use this file as a model for a chapter; DO NOT START BY removing its
%  contents and filling in your own text.
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter*{Lecture 6}
\addcontentsline{toc}{chapter}{Lecture 6}
\addtocounter{chapter}{6}
\addtocounter{section}{0}
%\numberwithin{section}{chapter}
\numberwithin{equation}{chapter}
\numberwithin{theorem}{chapter}

In this lecture we will embark on one of the most important modern applications of convex optimization: \textbf{machine learning}. The goal of machine learning is to develop methods to automatically {\em learn} a function
\begin{equation*}
 h\colon \mathcal{X}\to \mathcal{Y},
\end{equation*}
where $\mathcal{X}$ is a space of {\em inputs} or {\em features}, and $\mathcal{Y}$ consists of {\em outputs} or {\em responses}. The input space $\mathcal{X}$ is usually an $\R^n$, though the inputs could represent anything such as images, texts, emails, genome sequences, or networks, financial time series, or demographic data. The output could be either \textbf{quantitative} values, such as a temperature or the amount of some substance in the body, or \textbf{qualitative} or \textbf{categorical}, such as {YES, NO} or $\{0,1,2,3,4,5,6,7,8,9\}$ (for recognising spam or handwritten digits, respectively). The first type of problem is usually called \textbf{regression}, while the latter is called \textbf{classification}. Machine learning techniques underlie much of modern technology, from car electronics to online product recommendation systems and search engines.

\section{Supervised Learning}
In supervised learning, we have at our disposal a collection of input-output pairs
\begin{equation*}
  (\vct{x}_i, y_i) \in \mathcal{X}\times \mathcal{Y}, \ 1\leq i\leq m,
\end{equation*}
and the goal is to {\em learn} a function $h\colon \mathcal{X}\to \mathcal{Y}$ from this data. 
The given pairs $\{(\vct{x}_i,y_i)\}_{1\leq i\leq m}$ are called the \textbf{training set}.

\begin{example}(Handwriting recognition)
Given a dataset of pixel matrices, each representing a grey-scale image, with associated \textbf{labels} telling us for each image the number it represents, the task is to use this to train a computer program to recognise new numbers. Such classification tasks are often carried out using \textbf{deep neural networks}. 

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{images/letters.jpg}
\end{figure}

\end{example}

\begin{example}(Linear regression)
Recall from Lecture 1 the problem of finding a function of the form
\begin{equation*}
  Y = \beta_0+\beta_1X_1+\cdots +\beta_pX_p.
\end{equation*}
Given a set of input-output pairs $(\vct{x}_i,y_i)$, arranged in a matrix $\mtx{X}$ and a vector $\vct{y}$, we saw that we could {\em guess} the correct $\vct{\beta} = (\beta_0,\beta_1,\dots, \beta_p)^{\trans}$ by solving the {\em least-squares} optimization problem
\begin{equation*}
  \mathop{\minimize}_{\vct{\beta}} \norm{\mtx{X}\vct{\beta}-\vct{y}}_2^2.
\end{equation*}
By now, we know how to solve this problem using gradient descent.
\end{example}

\begin{example}
In text classification, the task is to decide to which of a given set of categories a given text belongs. The training data consists of a {\em bag of words}: this is a large sparse matrix, whose
columns represent words and the rows represent articles, with the $(i,j)$-th entry containing the number of times word $j$ is contained in text $i$. 

\begin{center}
\begin{tabular}{|r|c|c|}
 & Rooney & Boris \\
\hline 
 Article 1 & 5 & 0 \\
 Article 2 & 1 & 7 \\
\end{tabular}
\end{center}

For example, in the above set we would classify the first article as "Sports" and the second one as "Politics". One such training dataset is the
Reuters Corpus Volume I (RCV1), an archive of over 800,000 categorised newswire stories.

A typical binary classifier for such a problem would be a \textbf{linear classifier} of the form
\begin{equation*}
  h(\vct{x}) = \vct{w}^{\trans}\vct{x}-\tau,
\end{equation*} 
with $\vct{w}\in \R^n$ and $\tau\in \R$. Given a text, represented as a row of the dataset $\vct{x}$, it is classified into one of two classes $\{+1,-1\}$, depending on whether $h(\vct{x})>0$ or $h(\vct{x})<0$. 
\end{example}

Suppose we have the training data $\{\vct{x}_i,y_i\}_{1\leq i\leq m}$ and we found a candidate function $h\colon \mathcal{X}\to \mathcal{Y}$. How do we assess if this is a good fit? One usually assigns to the problem a \textbf{loss function} $\ell\colon \mathcal{Y}\times \mathcal{Y}\to \R_+$ that measures the mismatch of a prediction. One would then aim to find a function $h$ among a set of candidates that minimizes the loss when applying the function to the training data:

\begin{equation*}
  \mathop{\minimize}_{h} \ \frac{1}{m} \sum_{i=1}^m \ell(h(\vct{x}_i,y_i).
\end{equation*}

The form of the loss function depends on the problem at hand, but two typical candidates are the \textbf{square error} for regression problems,
\begin{equation*}
  \ell(h(\vct{x}),y) = (h(\vct{x})-y)^2,
\end{equation*}
and the indicator loss function
\begin{equation*}
  \mathbf{1}\{h(\vct{x})\neq y\},
\end{equation*}
where $\mathbf{1}\{A\}$ is the indication function, which takes the value $1$ if $A$ is true, and $0$ else. As this function is not continuous, in practice one often encounters the {\em log loss} function,
\begin{equation*}
  \ell(h(\vct{x}),y) = \log\left(1+e^{-h(\vct{x})y} \right).
\end{equation*}
Note that if $h(\vct{x})$ and $\vct{y}$ have the same sign (corresponding to a match), then the value of this function will be close to zero. 

Suppose we have a binary classification task at hand, with $\mathcal{Y}=\{-1,1\}$. We could {\em learn} the following function from our data:
\begin{equation*}
  h(\vct{x}) = \begin{cases}
    y_i & \text{ if } \vct{x}=\vct{x}_i,\\
    1 & \text{ otherwise.}
  \end{cases}
\end{equation*}
The \textbf{empirical misclassification risk} in for this problem is then $0$,
\begin{equation*}
  R(h) = \frac{1}{m} \sum_{i=1}^m \mathbf{1}\{h(\vct{x}_i\neq y_i\} = 0.
\end{equation*}
Nevertheless, this is not a good classifier: it will not perform very well outside of the training set. This is an example of \textbf{overfitting}: when the function is adapted too closely to the seen data. To remedy this, one often (randomly) splits the available data into a \textbf{training set} and a \textbf{test set}. The training set is used to find the function $h$, while the test set is for testing how good it is (in practise, one often adds a validation set, used to tune some parameters of the problem).

\begin{example}
In the linear regression problem with the quadratic loss function, we end up with the minimization problem
\begin{equation*}
  \mathop{\minimize}_{\vct{\beta}} \frac{1}{n} \sum_{i=1}^n (\vct{x}_i^{\trans}\vct{\beta}-y_i)^2 =\frac{1}{n}\norm{\mtx{X}\vct{\beta}-\vct{y}}_2^2.
\end{equation*}
This is precisely the problem encountered in Lecture 1.
\end{example}

\begin{example}
In the example of classifying a text into two classes using a linear classifier, we can look at the problem
\begin{equation*}
 \mathop{\minimize}_{\vct{w}, \tau} \frac{1}{n}\sum_{i=1}^m \mathbf{1}\{\vct{w}^{\trans}\vct{x}_i-\tau \neq y_i\}.
\end{equation*}
Since this function is not smooth or even continuous, we can work with the log-loss function described above,
\begin{equation*}
\mathop{\minimize}_{\vct{w}, \tau} \frac{1}{n} \sum_{i=1}^m \ell(\vct{w}^{\trans}\vct{x}_i-\tau, y_i).
\end{equation*}
This function can, in principle, be minimized using gradient descent or Newton's method. 
\end{example}

We have seen how a machine learning problem can be turned into an optimization problem. Unfortunately, when the amount of data is large, computing gradients and Hessians of the resulting functions can be very expensive. Suppose the function $h$ depends on parameters $\vct{w}$ which we want to optimize over, $h=h(\vct{x}; \vct{w})$, and denote the composition of the loss function $\ell$ with $h$ on the data $\vct{x}_i$ by
\begin{equation*}
  f_i(\vct{w}) := \ell(h(\vct{x}_i; \vct{w}),y_i).
\end{equation*}
We can then write our optimization problem as
\begin{equation*}
  \mathop{\minimize}_{\vct{w}} F(\vct{w}), \quad F(\vct{w}) = \frac{1}{m} \sum_{i=1}^m f_i(\vct{w}).
\end{equation*}
The gradient is then
\begin{equation*}
  \nabla F(\vct{w}) = \frac{1}{m} \sum_{i=1}^n \nabla f_i(\vct{w}).
\end{equation*}
For large datasets (for example, $m>10^6$ is not uncommon), computing all the gradients in each step is highly ineffective.

An old algorithm that has recently been revived in light of big data is \textbf{stochastic gradient descent}. The idea is to compute, at each step, only the gradient of {\em one} of the summands of the loss function:

\begin{equation*}
  \vct{w}_{k+1} = \vct{w}_k-\alpha_k \nabla f_{i_k}(\vct{w}_k),
\end{equation*}
where the index $i_k$ is {\em chosen at random} from $\{1,\dots,m\}$ at each step. 

Each step of this algorithm is clearly faster than gradient descent, but does it even work? It turns out that this algorithm converges quickly and that it is surprisingly effective on large datasets.


% %-----------------------------------------------------------------------
% % End of chap1.tex
% %-----------------------------------------------------------------------
